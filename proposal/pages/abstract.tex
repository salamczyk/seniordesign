\abstract{The purpose of this project is to use humanoid NAO robots to simulate a problem setting where one robot, Robot A, will model two or more behavioral states, and another robot, Robot B, will communicate and perform behaviors to move Robot A toward a target state. This project has implications in improving human/robot relations and interactions. The Vision Lab has two NAO robots, which will both be used in this project, each equipped with two five-megapixel cameras, four omnidirectional microphones, temperature sensor, gyroscope, accelerometer, and multiple position, tactile, force-resistive, and ultrasonic sensors. The NAO robots are fully programmable using Python 2.7 and the NAOqi API; there is also a GUI application called Choregraphe that can be used to make block diagrams with programmable blocks. Test controllers for the behaviors of each robot will be designed and implemented. Each controller will require a behavior module that manages behaviors and communications performed by the robot, a recognition module to classify the behaviors of the other robot, and a reinforcement module to adjust behaviors based on feedback from the other robot.
}
